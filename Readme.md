# Heterogeneous GPU Distributed Matrix Multiplication

This repository contains scripts and instructions for setting up and running a distributed matrix multiplication experiment using two AWS instances: one with an Nvidia GPU and one with an AMD GPU. The experiment utilizes MPI for inter-node communication and PyTorch for GPU-accelerated matrix operations.

## System Requirements

- AWS Instances:
  - Nvidia Node: `p2.xlarge` with Nvidia GPU
  - AMD Node: `g4ad.xlarge` with AMD GPU
- Operating System: Ubuntu (Recommended: Ubuntu 20.04 LTS)

## Setup Instructions

### 1. Prepare the Instances

Ensure both AWS instances are running Ubuntu. The instructions below assume Ubuntu 20.04 is installed.

### 2. Install Required Software

Each node has a specific setup script that installs all required software, including MPI, Python, and the appropriate GPU frameworks (CUDA for Nvidia, ROCm for AMD).

#### Nvidia Node Setup

1. SSH into your Nvidia instance.
2. Clone the repository:
   ```bash
   git clone 
   ```
3. Make the script executable:
   ```bash
   chmod +x setup_nvidia.sh
   ```
4. Run the setup script:
   ```bash
   sudo ./setup_nvidia.sh
   ```
5. Reboot the instance to ensure all drivers are properly loaded:
   ```bash
   sudo reboot
   ```

#### AMD Node Setup

1. SSH into your AMD instance.
2. Clone the repository:
   ```bash
   git clone 
   ```
3. Make the script executable:
   ```bash
   chmod +x setup_amd.sh
   ```
4. Run the setup script:
   ```bash
   sudo ./setup_amd.sh
   ```
5. Reboot the instance to ensure all drivers and ROCm installations are active:
   ```bash
   sudo reboot
   ```

### 3. Running the Experiment

After setting up both instances, follow these steps to run the matrix multiplication experiment:

1. Ensure both nodes are in the same VPC and security groups allow TCP communication between them.
2. Place the Python script `distributed_matrix_multiplication.py` on both nodes.
3. Use MPI to start the experiment across both nodes. Run the following command from the Nvidia node (acting as the master node):
   ```bash
   mpiexec -n 2 -hosts nvidia_node_hostname,amd_node_hostname python3 distributed_matrix_multiplication.py
   ```

## Monitoring and Results

- **Performance Metrics**: The script logs computation time, communication time, and GPU utilization for both nodes.
- **Output**: The final matrix and performance metrics are stored in designated output files specified in the Python script.

## Troubleshooting

- Ensure MPI is correctly installed and configured on both nodes.
- Verify that the security groups and network settings allow for proper MPI communication between the nodes.
- Check that CUDA and ROCm are correctly installed by running device query tests or sample programs provided by Nvidia and AMD respectively.

For more detailed troubleshooting, refer to the logs generated by the Python script and system logs for MPI and GPU drivers.

## Additional Resources

- [Nvidia CUDA Toolkit Documentation](https://developer.nvidia.com/cuda-toolkit)
- [AMD ROCm Documentation](https://rocmdocs.amd.com/)
- [MPI Documentation](https://www.mpi-forum.org/docs/)